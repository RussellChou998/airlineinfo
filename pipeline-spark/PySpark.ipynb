{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful commands inside of psql through the command line\n",
    "\n",
    "# \\l\n",
    "# \\dn\n",
    "# \\dt airwatch.* # see all tables in the airwatch schema, owned by Emily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to DB using Apache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Hit:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:2 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates InRelease  \n",
      "Hit:3 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Hit:4 https://packages.cloud.google.com/apt cloud-sdk InRelease                \n",
      "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease        \n",
      "Reading package lists... Done                      \n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Calculating upgrade... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  python3-crcmod\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -y update\n",
    "!sudo apt-get -y upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "openjdk-8-jdk-headless is already the newest version (8u312-b07-0ubuntu1~18.04).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  python3-crcmod\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -y install openjdk-8-jdk-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "    \n",
    "!tar xf spark-3.2.1-bin-hadoop3.2.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pyspark # quiet so there's less console spam\n",
    "!pip install -q findspark\n",
    "!pip install -q requests\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "--2022-03-29 22:06:40--  https://jdbc.postgresql.org/download/postgresql-42.3.2.jar\n",
      "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
      "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1040162 (1016K) [application/java-archive]\n",
      "Saving to: ‘postgresql-42.3.2.jar.14’\n",
      "\n",
      "postgresql-42.3.2.j 100%[===================>]   1016K  1.71MB/s    in 0.6s    \n",
      "\n",
      "2022-03-29 22:06:41 (1.71 MB/s) - ‘postgresql-42.3.2.jar.14’ saved [1040162/1040162]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://jdbc.postgresql.org/download/postgresql-42.3.2.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/project/spark-3.2.1-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark App\") \\\n",
    "    .config(\"spark.jars\", \"/project/postgresql-42.3.2.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark App\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"postgresql-42.3.2.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode this into the lamda protected S3 bucket\n",
    "\n",
    "DB_USERNAME = \"emilyvonbergen\"\n",
    "DB_PASSWORD = \"dataEngineering2022\"\n",
    "\n",
    "DB_HOSTNAME = \"airlinewatcherdb.cztfolrhsk2n.eu-west-2.rds.amazonaws.com\"\n",
    "DB_NAME = \"airlinewatcherdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTGRES_URI = 'jdbc:postgresql://' + DB_HOSTNAME + '/' + DB_USERNAME\n",
    "POSTGRES_URI = 'jdbc:postgresql://' + DB_HOSTNAME + '/' + 'airlinewatcherdb'\n",
    "DB_TABLE = 'airlinewatcherdb.airwatch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_country = spark.read.csv('schema-ready/country.csv', header=True)\n",
    "df_airline = spark.read.csv('schema-ready/airline.csv', header=True)\n",
    "df_airline_stock = spark.read.csv('schema-ready/airline_stock.csv', header=True)\n",
    "df_airport = spark.read.csv('schema-ready/airport.csv', header=True)\n",
    "df_reviews = spark.read.csv('schema-ready/reviews.csv', header=True)\n",
    "df_routes = spark.read.csv('schema-ready/routes.csv', header=True)\n",
    "df_tweets = spark.read.csv('schema-ready/tweets.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- ISO_code_2: string (nullable = true)\n",
      " |-- ISO_code_3: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_country.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+----------+----------+--------+\n",
      "|country_id|               name|ISO_code_2|ISO_code_3|  region|\n",
      "+----------+-------------------+----------+----------+--------+\n",
      "|         0|        Afghanistan|        AF|       AFG|    Asia|\n",
      "|         1|      Åland Islands|        AX|       ALA|  Europe|\n",
      "|         2|            Albania|        AL|       ALB|  Europe|\n",
      "|         3|            Algeria|        DZ|       DZA|  Africa|\n",
      "|         4|     American Samoa|        AS|       ASM| Oceania|\n",
      "|         5|            Andorra|        AD|       AND|  Europe|\n",
      "|         6|             Angola|        AO|       AGO|  Africa|\n",
      "|         7|           Anguilla|        AI|       AIA|Americas|\n",
      "|         8|         Antarctica|        AQ|       ATA|    null|\n",
      "|         9|Antigua and Barbuda|        AG|       ATG|Americas|\n",
      "|        10|          Argentina|        AR|       ARG|Americas|\n",
      "|        11|            Armenia|        AM|       ARM|    Asia|\n",
      "|        12|              Aruba|        AW|       ABW|Americas|\n",
      "|        13|          Australia|        AU|       AUS| Oceania|\n",
      "|        14|            Austria|        AT|       AUT|  Europe|\n",
      "|        15|         Azerbaijan|        AZ|       AZE|    Asia|\n",
      "|        16|            Bahamas|        BS|       BHS|Americas|\n",
      "|        17|            Bahrain|        BH|       BHR|    Asia|\n",
      "|        18|         Bangladesh|        BD|       BGD|    Asia|\n",
      "|        19|           Barbados|        BB|       BRB|Americas|\n",
      "+----------+-------------------+----------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = \"airlinewatcherdb.airwatch.\"\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "def insert_data(df, table):\n",
    "    cols = df.columns\n",
    "    df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", POSTGRES_URI) \\\n",
    "    .option(\"dbtable\", schema_name + table) \\\n",
    "    .option(\"user\", DB_USERNAME) \\\n",
    "    .option(\"password\", DB_PASSWORD) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jdbc:postgresql://airlinewatcherdb.cztfolrhsk2n.eu-west-2.rds.amazonaws.com/airlinewatcherdb'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSTGRES_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insert_data(df_country, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once above it working, then this cell can be run\n",
    "df_country = spark.read.csv('schema-ready/country.csv', header=True, inferSchema=True)\n",
    "df_airline = spark.read.csv('schema-ready/airline.csv', header=True, inferSchema=True)\n",
    "df_airline_stock = spark.read.csv('schema-ready/airline_stock.csv', header=True, inferSchema=True)\n",
    "df_airport = spark.read.csv('schema-ready/airport.csv', header=True, inferSchema=True)\n",
    "df_reviews = spark.read.csv('schema-ready/reviews.csv', header=True, inferSchema=True)\n",
    "df_routes = spark.read.csv('schema-ready/routes.csv', header=True, inferSchema=True)\n",
    "# df_tweets = spark.read.csv('schema-ready/tweets.csv', header=True)\n",
    "df_tweets = spark.read.option(\"multiline\", True).option('escape', \"\\\"\").csv('schema-ready/tweets.csv', header=True, inferSchema=True)\n",
    "\n",
    "insert_data(df_country, 'country')\n",
    "insert_data(df_airline, 'airline')\n",
    "insert_data(df_airline_stock, 'airline_stock')\n",
    "insert_data(df_airport, 'airport')\n",
    "insert_data(df_reviews, 'reviews') # this one might throw error, schema on the server needs to be changed to remove user_location in reviews table\n",
    "insert_data(df_routes, 'routes')\n",
    "insert_data(df_tweets, 'tweets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tweets_id', 'int'),\n",
       " ('comment', 'string'),\n",
       " ('retweet', 'int'),\n",
       " ('reply', 'int'),\n",
       " ('like', 'int'),\n",
       " ('quote', 'int'),\n",
       " ('airline_id', 'int')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# from pyspark import Row\n",
    "\n",
    "# dummy_df = spark.createDataFrame([\n",
    "#     Row(country_id=900, name='magicland', ISO_code_2='ML', ISO_code_3='MLD', region='earth')\n",
    "# ])\n",
    "\n",
    "# insert_data(dummy_df, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tweets_id: int, comment: string, retweet: int, reply: int, like: int, quote: int, airline_id: int]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test reading\n",
    "# same error here\n",
    "spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", POSTGRES_URI) \\\n",
    "    .option(\"user\", DB_USERNAME) \\\n",
    "    .option(\"password\", DB_PASSWORD) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"query\", \"select * from airwatch.tweets\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------+-----+----+-----+----------+\n",
      "|tweets_id|             comment|retweet|reply|like|quote|airline_id|\n",
      "+---------+--------------------+-------+-----+----+-----+----------+\n",
      "|        0|📍UPDATE: Long se...|     24|   30| 155|   16|      4296|\n",
      "|        1|Long security del...|     13|   30| 101|    4|      4296|\n",
      "|        2|UPDATE: website/ ...|      5|  191|  52|    6|      4296|\n",
      "|        3|Our website/app i...|      5|   94|  79|    5|      4296|\n",
      "|        4|CUSTOMER UPDATE: ...|      4|  153|  91|   15|      4296|\n",
      "|        5|Calling all from ...|      1|   14|  14|    0|      4296|\n",
      "|        6|     GO, GO, GO 🏃👇|      9|   31|  35|    7|      4296|\n",
      "|        7|Don't walk...RUN ...|     11|   43|  41|    4|      4296|\n",
      "|        8|@ Irish passenger...|      4|   13|  64|    2|      4296|\n",
      "|        9|🚨 FLASH SALE ALE...|      6|   22|  30|    1|      4296|\n",
      "|       10|Congratulations a...|      5|   27|  85|    1|      3320|\n",
      "|       11|The window view i...|     13|   16|  97|    1|      3320|\n",
      "|       12|The Algarve with ...|      6|   17|  58|    1|      3320|\n",
      "|       13|We are proud of o...|     33|   18| 149|    1|      3320|\n",
      "|       14|As the aid organi...|      9|   10|  76|    1|      3320|\n",
      "|       15|We are amazed by ...|      7|   13|  64|    2|      3320|\n",
      "|       16|Your summer outfi...|      8|   40|  43|    3|      3320|\n",
      "|       17|The window view i...|      7|   18|  88|    0|      3320|\n",
      "|       18|One of the highli...|      8|   18|  43|    1|      3320|\n",
      "|       19|Today is Random A...|      7|   18|  58|    2|      3320|\n",
      "+---------+--------------------+-------+-----+----+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", POSTGRES_URI) \\\n",
    "    .option(\"user\", DB_USERNAME) \\\n",
    "    .option(\"password\", DB_PASSWORD) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"query\", \"select * from airwatch.tweets\") \\\n",
    "    .load()\n",
    "\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|        airline_name|count_comment_twitter|\n",
      "+--------------------+---------------------+\n",
      "|            Wizz Air|                   10|\n",
      "|          Air France|                   10|\n",
      "|             easyJet|                   10|\n",
      "|           Lufthansa|                   10|\n",
      "|Norwegian Air Int...|                   10|\n",
      "|             Ryanair|                   10|\n",
      "|              TUIfly|                   10|\n",
      "|Aeroflot Russian ...|                   10|\n",
      "|    Turkish Airlines|                    8|\n",
      "+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_q2 = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", POSTGRES_URI) \\\n",
    "    .option(\"user\", DB_USERNAME) \\\n",
    "    .option(\"password\", DB_PASSWORD) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"query\", \"\\\n",
    "    SELECT a.name as airline_name\\\n",
    "    , count(distinct b.comment) as count_comment_twitter\\\n",
    "    FROM  airwatch.airline a \\\n",
    "    left join airwatch.tweets as b on a.airline_id = b.airline_id\\\n",
    "    where a.airline_id is not null and b.comment is not null\\\n",
    "    group by 1\\\n",
    "    order by 2 desc\\\n",
    "    limit 100\\\n",
    "    \") \\\n",
    "    .load()\n",
    "\n",
    "df_q2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|airline_id|country_id|                name|\n",
      "+----------+----------+--------------------+\n",
      "|        -1|       153|             Unknown|\n",
      "|         2|       235|         135 Airways|\n",
      "|         3|       206|       1Time Airline|\n",
      "|         4|       234|2 Sqn No 1 Elemen...|\n",
      "|         5|       183|     213 Flight Unit|\n",
      "|         6|       183|223 Flight Unit S...|\n",
      "|         7|       183|   224th Flight Unit|\n",
      "|         8|       234|         247 Jet Ltd|\n",
      "|         9|       235|         3D Aviation|\n",
      "|        10|       235|         40-Mile Air|\n",
      "|        11|       220|              4D Air|\n",
      "|        12|        40|611897 Alberta Li...|\n",
      "|        13|        13|    Ansett Australia|\n",
      "|        14|       200|Abacus International|\n",
      "|        15|        21|     Abelag Aviation|\n",
      "|        16|       234|      Army Air Corps|\n",
      "|        17|        40|Aero Aviation Cen...|\n",
      "|        18|       143|Aero Servicios Ej...|\n",
      "|        19|       143|         Aero Biniza|\n",
      "|        20|       209|       Aero Albatros|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", POSTGRES_URI) \\\n",
    "    .option(\"user\", DB_USERNAME) \\\n",
    "    .option(\"password\", DB_PASSWORD) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"query\", \"select * from airwatch.airline\") \\\n",
    "    .load()\n",
    "\n",
    "test.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
